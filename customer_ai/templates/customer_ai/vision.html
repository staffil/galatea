{% load static %} 

<!DOCTYPE html>
<html lang="ko">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Vision Chat UI</title>
    <link rel="stylesheet" href="{% static 'css/customer_ai/vision.css' %}">

</head>
<body>
    <!-- í—¤ë” -->
    <header>
        {% if not user.is_authenticated %}
          {% include "common/notLoginHeader.html" %}
        {% else %}
          {% include "common/loginHeader.html" %}
        {% endif %}
    </header>

    <div class="container">
        <!-- ì‚¬ì´ë“œë°” -->
        <aside class="sidebar">
            <h3>ğŸ¯ ëª¨ë“œ ì„ íƒ</h3>
            <div class="mode-option">
                <input type="radio" name="mode" onclick="location.href='/customer_ai/chat/{{llm_id}}';">
                <label>ğŸ’¬ TEXT MODE</label>
            </div>
            <div class="mode-option active">
                <input type="radio" name="mode" checked onclick="location.href='/customer_ai/vision/{{llm_id}}';">
                <label>ğŸ‘ï¸ VISION MODE</label>
            </div>
        </aside>

        <!-- ë©”ì¸ ì±„íŒ… ì˜ì—­ -->
        <main class="chat-container">
            <div class="chat-header">
                <div class="ai-avatar">ğŸ‘ï¸</div>
                <h1 class="chat-title">{{ llm.name }} ë¹„ì „ ëŒ€í™”í•˜ê¸°</h1>
            </div>
            
            <p class="chat-subtitle">ì¹´ë©”ë¼ë¡œ ì‹¤ì‹œê°„ ëŒ€í™”í•´ë³´ì„¸ìš”</p>

            <!-- ë¹„ë””ì˜¤ ì»¨í…Œì´ë„ˆ - ì¢Œìš° ë¶„í•  -->
            <div class="video-container">
                <!-- AI ì´ë¯¸ì§€ ì„¹ì…˜ -->
                <div class="ai-image-section">
                    <div class="section-title">ğŸ¤– AI ìºë¦­í„°</div>
                    {% if llm.llm_image %}
                        <img src="{{ llm.llm_image.url }}" alt="AI ì´ë¯¸ì§€" class="ai-image" />
                    {% else %}
                        <div class="no-image">ìƒì„±ëœ ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤</div>
                    {% endif %}
                </div>

                <!-- ì›¹ìº  ì„¹ì…˜ -->
                <div class="webcam-section">
                    <div class="section-title">ğŸ“¹ ì‹¤ì‹œê°„ ì¹´ë©”ë¼</div>
                    <video id="webcam" autoplay playsinline></video>
                </div>
            </div>

            <button id="toggle-vision-btn">ë¹„ì „ ëª¨ë“œ ì‹œì‘</button>
            
            <div id="vision-result">ë¹„ì „ ëª¨ë“œ ì¤€ë¹„ ì¤‘...</div>

            <hr>
<div id="recognized-text"></div>
<div id="response"></div>
              <!-- ì˜¤ë””ì˜¤ í”Œë ˆì´ì–´ë¥¼ í…ìŠ¤íŠ¸ ì…ë ¥ì°½ ìœ„ë¡œ ì´ë™ -->
            <div class="audio-player" id="audio-container" style="display: none;">
                <audio id="tts-audio" controls></audio>
            </div>

              <!-- ë§ˆì´í¬ë¥¼ í…ìŠ¤íŠ¸ ì…ë ¥ì°½ ì•„ë˜ë¡œ ì´ë™ -->
            <div class="record-container">
                <button class="record-button" id="record-btn" onclick="toggleRecording()">
                    <span class="record-icon" id="record-icon">ğŸ¤</span>
                </button>
            </div>
            <div class="record-status" id="record-status">ë…¹ìŒì„ ì‹œì‘í•˜ë ¤ë©´ ë²„íŠ¼ì„ ëˆ„ë¥´ì„¸ìš”</div>
        </main>
    </div>

  <script>
        const video = document.getElementById('webcam');
        const canvas = document.createElement('canvas');
        const toggleBtn = document.getElementById('toggle-vision-btn');
        const visionResult = document.getElementById('vision-result');
        const ttsAudio = document.getElementById('tts-audio');
        const responseDiv = document.getElementById('response');

        let streaming = false;
        let intervalId = null;
        let isVisionRunning = false;
        let latestVisionResult = '';

        let isProcessingVision = false; // ì´ë¯¸ì§€ ë¶„ì„ ì¤‘ë³µ ë°©ì§€ìš©
        let isPlayingAudio = false;     // ìŒì„± ì¬ìƒ ìƒíƒœ

        // ì›¹ìº  ì‹œì‘
        async function startWebcam() {
            try {
                const stream = await navigator.mediaDevices.getUserMedia({ video: true, audio: false });
                video.srcObject = stream;
                streaming = true;
            } catch (err) {
                alert('ì›¹ìº  ì ‘ê·¼ ì‹¤íŒ¨: ' + err);
            }
        }

        // ì›¹ìº  ì¤‘ì§€
        function stopWebcam() {
            if (video.srcObject) {
                video.srcObject.getTracks().forEach(track => track.stop());
            }
            streaming = false;
        }

        // ì´ë¯¸ì§€ ë¶„ì„ ì„œë²„ ì „ì†¡ í•¨ìˆ˜
        async function sendFrameToServer() {
            if (!streaming) return;
            if (isProcessingVision) return;
            if (isPlayingAudio) return;  // ìŒì„± ì¬ìƒ ì¤‘ì¼ ë•Œ ë¶„ì„ ì¤‘ë‹¨

            isProcessingVision = true;

            canvas.width = video.videoWidth;
            canvas.height = video.videoHeight;
            const ctx = canvas.getContext('2d');
            ctx.drawImage(video, 0, 0);

            canvas.toBlob(async (blob) => {
                if (!blob) {
                    isProcessingVision = false;
                    return;
                }

                const formData = new FormData();
                formData.append('image', blob, 'frame.jpg');

                try {
                    const response = await fetch('/customer_ai/vision_process/', {
                        method: 'POST',
                        body: formData
                    });
                    if (!response.ok) throw new Error('ì„œë²„ ì‘ë‹µ ì˜¤ë¥˜');
                    const data = await response.json();
                    visionResult.innerText = 'ë¶„ì„ ê²°ê³¼: ' + data.result;
                    latestVisionResult = data.result;
                } catch (err) {
                    console.error('Vision error:', err);
                    visionResult.innerText = 'ë¶„ì„ ì˜¤ë¥˜ ë°œìƒ';
                } finally {
                    isProcessingVision = false;
                }
            }, 'image/jpeg');
        }

        // GPT ì‘ë‹µ ìš”ì²­ (Vision ê²°ê³¼ í¬í•¨)
        async function sendText(text) {
            if (!text || !text.trim()) return;
            const currentLlmId = "{{ llm_id }}";
          console.log("sendText í˜¸ì¶œë¨, text:", text);
              console.log("latestVisionResult:", latestVisionResult);

            isPlayingAudio = true;  // ìŒì„± ì¬ìƒ í”Œë˜ê·¸ ì„¤ì •

            const formData = new FormData();
            formData.append('text', text);
            formData.append('vision', latestVisionResult);
            formData.append('llm_id', currentLlmId);


            try {
                const res = await fetch('/customer_ai/generate_response/', {
                    method: 'POST',
                    body: formData,
                });
                if (!res.ok) throw new Error('ì‘ë‹µ ì‹¤íŒ¨');
                const data = await res.json();

                responseDiv.innerText = 'AI: ' + data.ai_text;
                if (data.audio_url) {
                    ttsAudio.src = data.audio_url + '?t=' + new Date().getTime(); // ìºì‹± ë°©ì§€
                    await ttsAudio.play();
                }
            } catch (err) {
                responseDiv.innerText = 'ì‘ë‹µ ì¤‘ ì˜¤ë¥˜ ë°œìƒ';
                console.error(err);
            }
        }

        // ì˜¤ë””ì˜¤ ì¬ìƒ ì¢…ë£Œ ì‹œì  í”Œë˜ê·¸ í•´ì œ
        ttsAudio.addEventListener('ended', () => {
            isPlayingAudio = false;
        });

        // ë…¹ìŒ ë° ë¬´ìŒ ê°ì§€
        async function startRecording() {
            try {
                const micStream = await navigator.mediaDevices.getUserMedia({ audio: true });
                const mediaRecorder = new MediaRecorder(micStream, { mimeType: 'audio/webm;codecs=opus' });
                let audioChunks = [];

                mediaRecorder.ondataavailable = e => {
                    if (e.data && e.data.size > 0) {
                        audioChunks.push(e.data);
                    }
                };

                mediaRecorder.onstop = async () => {
                    const audioBlob = new Blob(audioChunks, { type: 'audio/webm' });
                    const formData = new FormData();
                    formData.append('audio', audioBlob, 'recorded.webm');

                    try {
                        const response = await fetch('/customer_ai/upload_audio/', {
                            method: 'POST',
                            body: formData,
                        });
                        const data = await response.json();
                        if (response.ok) {
                            console.log('Transcription:', data.text);
                            sendText(data.text);
                        } else {
                            console.error('Error:', data.error);
                        }
                    } catch (err) {
                        console.error('Fetch error:', err);
                    }
                };

                mediaRecorder.start();

                // ì˜ˆ: 5ì´ˆ í›„ ë…¹ìŒ ì¤‘ì§€
                setTimeout(() => {
                    mediaRecorder.stop();
                    micStream.getTracks().forEach(track => track.stop());
                }, 5000);

            } catch (err) {
                console.error('Could not start recording:', err);
            }
        }

        // ë¹„ì „ ëª¨ë“œ í† ê¸€ ë²„íŠ¼ ì´ë²¤íŠ¸
        toggleBtn.addEventListener('click', () => {
            if (!isVisionRunning) {
                startVisionMode();
            } else {
                stopVisionMode();
            }
            isVisionRunning = !isVisionRunning;
        });

        // ë¹„ì „ ëª¨ë“œ ì‹œì‘
        async function startVisionMode() {
            if (!streaming) await startWebcam();
            visionResult.innerText = 'ë¹„ì „ ëª¨ë“œ ì‹¤í–‰ ì¤‘...';
            intervalId = setInterval(sendFrameToServer, 1500); // 1.5ì´ˆë§ˆë‹¤ í”„ë ˆì„ ë¶„ì„
            await startRecording();
            toggleBtn.innerText = 'ë¹„ì „ ëª¨ë“œ ì¤‘ì§€';
        }

        // ë¹„ì „ ëª¨ë“œ ì¤‘ì§€
        function stopVisionMode() {
            clearInterval(intervalId);
            stopWebcam();
            visionResult.innerText = 'ë¹„ì „ ëª¨ë“œ ì¤‘ì§€ë¨';
            toggleBtn.innerText = 'ë¹„ì „ ëª¨ë“œ ì‹œì‘';
        }

        let mediaRecorder;
        let audioChunks = [];
        let isRecording = false;
        let stream;

        function toggleRecording() {
            const recordBtn = document.getElementById("record-btn");
            const recordStatus = document.getElementById("record-status");

            if (!isRecording) {
                navigator.mediaDevices
                    .getUserMedia({ audio: true })
                    .then((s) => {
                        stream = s;
                        mediaRecorder = new MediaRecorder(stream);
                        audioChunks = [];
                        mediaRecorder.start();
                        isRecording = true;

                        recordBtn.querySelector(".record-icon").textContent = "â¹";
                        recordBtn.classList.add("recording");
                        recordBtn.parentElement.classList.add("recording");
                        recordStatus.textContent = "ë…¹ìŒ ì¤‘... ë‹¤ì‹œ ëˆ„ë¥´ë©´ ì¢…ë£Œë©ë‹ˆë‹¤";

                        mediaRecorder.addEventListener("dataavailable", (event) => {
                            audioChunks.push(event.data);
                        });

                        mediaRecorder.addEventListener("stop", () => {
                            const audioBlob = new Blob(audioChunks, { type: "audio/wav" });
                            const formData = new FormData();
                            formData.append("audio", audioBlob, "recorded.wav");

                            fetch("/customer_ai/upload_audio/", {
                                method: "POST",
                                body: formData,
                            })
                            .then((res) => res.json())
                            .then((data) => {
                                document.getElementById("recognized-text").textContent = "ì¸ì‹ëœ í…ìŠ¤íŠ¸: " + data.text;
                                sendText(data.text);
                            });
                        });
                    })
                    .catch((err) => {
                        alert("ë§ˆì´í¬ ê¶Œí•œì„ í—ˆìš©í•´ì£¼ì„¸ìš”.");
                        console.error(err);
                    });
            } else {
                mediaRecorder.stop();
                isRecording = false;
                recordBtn.querySelector(".record-icon").textContent = "ğŸ¤";
                recordBtn.classList.remove("recording");
                recordBtn.parentElement.classList.remove("recording");
                recordStatus.textContent = "ë…¹ìŒì„ ì‹œì‘í•˜ë ¤ë©´ ë²„íŠ¼ì„ ëˆ„ë¥´ì„¸ìš”";
            }
        }
    </script>
</body>
</html>